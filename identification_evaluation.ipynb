{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f414733f-4f1c-42fe-ab78-b2627f733c0a",
   "metadata": {},
   "source": [
    "# Identification evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5234456-5abe-4d10-99ba-28b5196176ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175b6635-86d9-41a6-b58c-53167efd6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.identification import nearest_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff797a0-fdda-4c8a-88f1-d9c75384c6de",
   "metadata": {},
   "source": [
    "### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98aa34f0-afd6-4886-afb6-8c5a70516ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RECORDINGS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb68037-a243-4d4e-aea6-08f9909553b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_in_system: list[torch.Tensor] = []\n",
    "samples_to_test: list[dict] = []\n",
    "users_list: list[str] = []\n",
    "\n",
    "for subdir in os.listdir('embedings/embeddings_180_noise'):\n",
    "    subdir_root = os.path.join('embedings/embeddings_180_noise', subdir)\n",
    "    for user_dir in os.listdir(subdir_root):\n",
    "        user_root = os.path.join(subdir_root, user_dir)\n",
    "        if not os.path.isdir(user_root):\n",
    "            continue\n",
    "        user_samples = torch.load(os.path.join(user_root, 'tensor.pt')).squeeze()\n",
    "        if user_samples.shape[0] < N_RECORDINGS + 1:\n",
    "            continue\n",
    "        users_list.append(user_dir)\n",
    "        samples_in_system.append(user_samples[:N_RECORDINGS])\n",
    "        samples_to_test.append({\n",
    "            \"user_dir\": user_dir,\n",
    "            'samples': user_samples[N_RECORDINGS:],\n",
    "            'subdir': subdir,\n",
    "        })\n",
    "\n",
    "samples_in_system = torch.stack(samples_in_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49c28dd-277e-4db8-8f89-3f032aefddd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([126, 10, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_in_system.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e228ccc-7304-4de8-b371-c190b9d8d6b0",
   "metadata": {},
   "source": [
    "### Evaluate for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1612f6-c938-4730-ae7f-c0312a3a9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146cc5d3-ac89-42b2-96fb-c77003ad2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_ala_recall(conf_matrix: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates \"ala recall\" for each user\n",
    "    (i.e. part of user's samples identified correctly)\n",
    "    and returns mean across all users\n",
    "    \n",
    "    Args:\n",
    "        conf_matrix (2D array): Confusion matrix whose i-th row and j-th column entry indicates\n",
    "            the number of samples with true label being i-th class and predicted label being j-th class.\n",
    "            (i.e. as in scikit-learn)\n",
    "    \"\"\"\n",
    "    n = conf_matrix.shape[0]\n",
    "    if conf_matrix.shape != (n,n):\n",
    "        raise ValueError(\"Input matrix must be square\")\n",
    "    diag = conf_matrix[np.arange(n), np.arange(n)]\n",
    "    return np.nanmean(diag / conf_matrix.sum(axis=1))\n",
    "\n",
    "\n",
    "def mean_ala_precision(conf_matrix: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates \"ala precision\" for each user\n",
    "    (i.e. ratio between number of user's correctly classified samples\n",
    "    and number of other users' samples classified as the user)\n",
    "    and returns mean across all users\n",
    "    \n",
    "    Args:\n",
    "        conf_matrix (2D array): Confusion matrix whose i-th row and j-th column entry indicates\n",
    "            the number of samples with true label being i-th class and predicted label being j-th class.\n",
    "            (i.e. as in scikit-learn)\n",
    "    \"\"\"\n",
    "    n = conf_matrix.shape[0]\n",
    "    if conf_matrix.shape != (n,n):\n",
    "        raise ValueError(\"Input matrix must be square\")\n",
    "    diag = conf_matrix[np.arange(n), np.arange(n)]\n",
    "    return np.nanmean(diag / conf_matrix.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655a0edc-0bd9-43aa-a685-c72a0fbd7900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 135.09it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 1181.11it/s]\n",
      "/tmp/ipykernel_6350/1334850639.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nanmean(diag / conf_matrix.sum(axis=1))\n",
      "/tmp/ipykernel_6350/1334850639.py:35: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nanmean(diag / conf_matrix.sum(axis=0))\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 1029.47it/s]\n",
      "/tmp/ipykernel_6350/1334850639.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nanmean(diag / conf_matrix.sum(axis=1))\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 216.30it/s]\n",
      "/tmp/ipykernel_6350/1334850639.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nanmean(diag / conf_matrix.sum(axis=1))\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 594.81it/s]\n",
      "/tmp/ipykernel_6350/1334850639.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nanmean(diag / conf_matrix.sum(axis=1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mean recall</th>\n",
       "      <th>mean precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.550446</td>\n",
       "      <td>0.408284</td>\n",
       "      <td>0.384733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean</th>\n",
       "      <td>0.477654</td>\n",
       "      <td>0.460484</td>\n",
       "      <td>0.280416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>echo</th>\n",
       "      <td>0.459906</td>\n",
       "      <td>0.425141</td>\n",
       "      <td>0.250159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>0.678455</td>\n",
       "      <td>0.675624</td>\n",
       "      <td>0.190169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noise</th>\n",
       "      <td>0.275457</td>\n",
       "      <td>0.234738</td>\n",
       "      <td>0.217449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  mean recall  mean precision\n",
       "all       0.550446     0.408284        0.384733\n",
       "clean     0.477654     0.460484        0.280416\n",
       "echo      0.459906     0.425141        0.250159\n",
       "language  0.678455     0.675624        0.190169\n",
       "noise     0.275457     0.234738        0.217449"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare results table\n",
    "\n",
    "result_rows = [\"all\", \"clean\", \"echo\", \"language\", \"noise\"]\n",
    "result_cols = [\"accuracy\", \"mean recall\", \"mean precision\"]\n",
    "results = pd.DataFrame(np.full((len(result_rows), len(result_cols)), fill_value=-1.0), index=result_rows, columns=result_cols)\n",
    "\n",
    "# obtain results for each split name: \"all\", \"clean\", \"echo\", \"language\", \"noise\"\n",
    "\n",
    "for split_name in result_rows:\n",
    "\n",
    "    # initialize lists of true and predicted users' IDs\n",
    "    true_users = []\n",
    "    predicted_users = []\n",
    "\n",
    "    # iterare over users and each user's samples to get true and predicted user's IDs\n",
    "    for user_dict in tqdm(samples_to_test):\n",
    "        user_id = user_dict[\"user_dir\"]\n",
    "        for test_emb in user_dict['samples']:\n",
    "            if split_name != 'all':\n",
    "                # filter out if not this subdir\n",
    "                if user_dict[\"subdir\"] != split_name:\n",
    "                    continue\n",
    "            true_users.append(user_id)\n",
    "            index, distance = nearest_tensor(target=test_emb, embeddings=samples_in_system, thresh=THRESHOLD)\n",
    "            if (index, distance) == (0, 0):\n",
    "                predicted_users.append(-1)\n",
    "            else:\n",
    "                predicted_users.append(users_list[index])\n",
    "\n",
    "    # calculate users' confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_pred=predicted_users, y_true=true_users)\n",
    "\n",
    "    # get accuracy, recall, precision\n",
    "    results.loc[split_name, \"accuracy\"] = accuracy_score(y_pred=predicted_users, y_true=true_users)\n",
    "    results.loc[split_name, \"mean recall\"] = mean_ala_recall(conf_matrix)\n",
    "    results.loc[split_name, \"mean precision\"] = mean_ala_precision(conf_matrix)\n",
    "\n",
    "# show results\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de352eb-573a-4cc2-adfb-156035d15340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrr}\\n\\\\toprule\\n & accuracy & mean recall & mean precision \\\\\\\\\\n\\\\midrule\\nall & 0.550446 & 0.408284 & 0.384733 \\\\\\\\\\nclean & 0.477654 & 0.460484 & 0.280416 \\\\\\\\\\necho & 0.459906 & 0.425141 & 0.250159 \\\\\\\\\\nlanguage & 0.678455 & 0.675624 & 0.190169 \\\\\\\\\\nnoise & 0.275457 & 0.234738 & 0.217449 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d9804-00fe-49c8-af8c-d4169c6d1a57",
   "metadata": {},
   "source": [
    "### Evaluate for denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd02bf8-c476-43b8-a4b2-7447dd58231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_in_system: list[torch.Tensor] = []\n",
    "samples_to_test: list[dict] = []\n",
    "users_list: list[str] = []\n",
    "\n",
    "for subdir in os.listdir('embedings/embeddings_180_denoise/'):\n",
    "    subdir_root = os.path.join('embedings/embeddings_180_denoise/', subdir)\n",
    "    for user_dir in os.listdir(subdir_root):\n",
    "        user_root = os.path.join(subdir_root, user_dir)\n",
    "        if not os.path.isdir(user_root):\n",
    "            continue\n",
    "        user_samples = torch.load(os.path.join(user_root, 'tensor.pt')).squeeze()\n",
    "        if user_samples.shape[0] < N_RECORDINGS + 1:\n",
    "            continue\n",
    "        users_list.append(user_dir)\n",
    "        samples_in_system.append(user_samples[:N_RECORDINGS])\n",
    "        samples_to_test.append({\n",
    "            \"user_dir\": user_dir,\n",
    "            'samples': user_samples[N_RECORDINGS:],\n",
    "            'subdir': subdir,\n",
    "        })\n",
    "\n",
    "samples_in_system = torch.stack(samples_in_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8423af7-ad1f-4d9d-a140-695826988ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 132.68it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 1219.92it/s]\n",
      "/tmp/ipykernel_6350/1334850639.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nanmean(diag / conf_matrix.sum(axis=1))\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 1048.69it/s]\n",
      "/tmp/ipykernel_6350/1334850639.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nanmean(diag / conf_matrix.sum(axis=1))\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 236.24it/s]\n",
      "/tmp/ipykernel_6350/1334850639.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nanmean(diag / conf_matrix.sum(axis=1))\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 126/126 [00:00<00:00, 690.44it/s]\n",
      "/tmp/ipykernel_6350/1334850639.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.nanmean(diag / conf_matrix.sum(axis=1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>mean recall</th>\n",
       "      <th>mean precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>0.414120</td>\n",
       "      <td>0.323063</td>\n",
       "      <td>0.303418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean</th>\n",
       "      <td>0.310056</td>\n",
       "      <td>0.338732</td>\n",
       "      <td>0.169522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>echo</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.351481</td>\n",
       "      <td>0.167136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>language</th>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.506174</td>\n",
       "      <td>0.165632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noise</th>\n",
       "      <td>0.216710</td>\n",
       "      <td>0.205802</td>\n",
       "      <td>0.198417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          accuracy  mean recall  mean precision\n",
       "all       0.414120     0.323063        0.303418\n",
       "clean     0.310056     0.338732        0.169522\n",
       "echo      0.375000     0.351481        0.167136\n",
       "language  0.509539     0.506174        0.165632\n",
       "noise     0.216710     0.205802        0.198417"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare results table\n",
    "\n",
    "result_rows = [\"all\", \"clean\", \"echo\", \"language\", \"noise\"]\n",
    "result_cols = [\"accuracy\", \"mean recall\", \"mean precision\"]\n",
    "results_denoised = pd.DataFrame(np.full((len(result_rows), len(result_cols)), fill_value=-1.0), index=result_rows, columns=result_cols)\n",
    "\n",
    "# obtain results for each split name: \"all\", \"clean\", \"echo\", \"language\", \"noise\"\n",
    "\n",
    "for split_name in result_rows:\n",
    "\n",
    "    # initialize lists of true and predicted users' IDs\n",
    "    true_users = []\n",
    "    predicted_users = []\n",
    "\n",
    "    # iterare over users and each user's samples to get true and predicted user's IDs\n",
    "    for user_dict in tqdm(samples_to_test):\n",
    "        user_id = user_dict[\"user_dir\"]\n",
    "        for test_emb in user_dict['samples']:\n",
    "            if split_name != 'all':\n",
    "                # filter out if not this subdir\n",
    "                if user_dict[\"subdir\"] != split_name:\n",
    "                    continue\n",
    "            true_users.append(user_id)\n",
    "            index, distance = nearest_tensor(target=test_emb, embeddings=samples_in_system, thresh=THRESHOLD)\n",
    "            if (index, distance) == (0, 0):\n",
    "                predicted_users.append(-1)\n",
    "            else:\n",
    "                predicted_users.append(users_list[index])\n",
    "\n",
    "    # calculate users' confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_pred=predicted_users, y_true=true_users)\n",
    "\n",
    "    # get accuracy, recall, precision\n",
    "    results_denoised.loc[split_name, \"accuracy\"] = accuracy_score(y_pred=predicted_users, y_true=true_users)\n",
    "    results_denoised.loc[split_name, \"mean recall\"] = mean_ala_recall(conf_matrix)\n",
    "    results_denoised.loc[split_name, \"mean precision\"] = mean_ala_precision(conf_matrix)\n",
    "\n",
    "# show results\n",
    "\n",
    "results_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d70ada-44f4-40ab-a264-d6a392ea900a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrr}\\n\\\\toprule\\n & accuracy & mean recall & mean precision \\\\\\\\\\n\\\\midrule\\nall & 0.414120 & 0.323063 & 0.303418 \\\\\\\\\\nclean & 0.310056 & 0.338732 & 0.169522 \\\\\\\\\\necho & 0.375000 & 0.351481 & 0.167136 \\\\\\\\\\nlanguage & 0.509539 & 0.506174 & 0.165632 \\\\\\\\\\nnoise & 0.216710 & 0.205802 & 0.198417 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_denoised.to_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83f9ed-acaf-413b-a9b5-426bded89029",
   "metadata": {},
   "source": [
    "### Evaluate our embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4025e4ad-cbff-4a19-9703-de854243dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_in_system: list[torch.Tensor] = []\n",
    "samples_to_test: list[dict] = []\n",
    "users_list: list[str] = []\n",
    "\n",
    "for subdir in os.listdir('embedings/embeddings_180_noise'):\n",
    "    subdir_root = os.path.join('embedings/embeddings_180_noise', subdir)\n",
    "    for user_dir in os.listdir(subdir_root):\n",
    "        user_root = os.path.join(subdir_root, user_dir)\n",
    "        if not os.path.isdir(user_root):\n",
    "            continue\n",
    "        user_samples = torch.load(os.path.join(user_root, 'tensor.pt')).squeeze()\n",
    "        if user_samples.shape[0] < N_RECORDINGS + 1:\n",
    "            continue\n",
    "        users_list.append(user_dir)\n",
    "        samples_in_system.append(user_samples[:N_RECORDINGS])\n",
    "        samples_to_test.append({\n",
    "            \"user_dir\": user_dir,\n",
    "            'samples': user_samples[N_RECORDINGS:],\n",
    "            'subdir': subdir,\n",
    "        })\n",
    "\n",
    "for subdir in os.listdir('nasze_emb'):\n",
    "    subdir_root = os.path.join('nasze_emb', subdir)\n",
    "    for user_dir in os.listdir(subdir_root):\n",
    "        user_root = os.path.join(subdir_root, user_dir)\n",
    "        if not os.path.isdir(user_root):\n",
    "            continue\n",
    "        user_samples = torch.load(os.path.join(user_root, 'tensor.pt')).squeeze()\n",
    "        if user_samples.shape[0] < N_RECORDINGS + 1:\n",
    "            continue\n",
    "        users_list.append(user_dir)\n",
    "        samples_in_system.append(user_samples[:N_RECORDINGS])\n",
    "        samples_to_test.append({\n",
    "            \"user_dir\": user_dir,\n",
    "            'samples': user_samples[N_RECORDINGS:],\n",
    "            'subdir': subdir,\n",
    "        })\n",
    "\n",
    "samples_in_system = torch.stack(samples_in_system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f63d98eb-44f6-4f77-bad7-b0c3dc2be320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hubert_Baran',\n",
       " 'Bianka_Kowalska',\n",
       " 'Daniil_Hardzetski',\n",
       " 'Hubert_Baran',\n",
       " 'Bianka_Kowalska',\n",
       " 'Daniil_Hardzetski']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_list[-6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62dec743-62fa-4ea3-8848-3cdda17f9b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 135/135 [00:00<00:00, 147.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bianka_Kowalska</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hubert_Baran</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daniil_Hardzetski</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.423077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     recall  precision\n",
       "Bianka_Kowalska    0.533333   0.133333\n",
       "Hubert_Baran       0.833333   0.555556\n",
       "Daniil_Hardzetski  0.611111   0.423077"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare results table\n",
    "\n",
    "result_rows = [\"Bianka_Kowalska\", \"Hubert_Baran\", \"Daniil_Hardzetski\"]\n",
    "result_cols = [\"recall\", \"precision\"]\n",
    "our_results = pd.DataFrame(np.full((len(result_rows), len(result_cols)), fill_value=-1.0), index=result_rows, columns=result_cols)\n",
    "\n",
    "# obtain results results for all users\n",
    "\n",
    "# initialize lists of true and predicted users' IDs\n",
    "true_users = []\n",
    "predicted_users = []\n",
    "\n",
    "# iterare over users and each user's samples to get true and predicted user's IDs\n",
    "for user_dict in tqdm(samples_to_test):\n",
    "    user_id = user_dict[\"user_dir\"]\n",
    "    for test_emb in user_dict['samples']:\n",
    "        true_users.append(user_id)\n",
    "        index, distance = nearest_tensor(target=test_emb, embeddings=samples_in_system, thresh=THRESHOLD)\n",
    "        if (index, distance) == (0, 0):\n",
    "            predicted_users.append(-1)\n",
    "        else:\n",
    "            predicted_users.append(users_list[index])\n",
    "\n",
    "for user_name in result_rows:\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for true_user, pred_user in zip(true_users, predicted_users):\n",
    "        if (true_user == user_name) and (pred_user == user_name):\n",
    "            TP += 1\n",
    "        elif (true_user == user_name) and (pred_user != user_name):\n",
    "            FN += 1\n",
    "        elif (true_user != user_name) and (pred_user == user_name):\n",
    "            FP += 1\n",
    "    our_results.loc[user_name, \"recall\"] = TP / (TP + FN)\n",
    "    our_results.loc[user_name, \"precision\"] = TP / (TP + FP)\n",
    "\n",
    "# show results\n",
    "\n",
    "our_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b594202c-001a-4b52-9c7c-1d40903b4182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrr}\\n\\\\toprule\\n & recall & precision \\\\\\\\\\n\\\\midrule\\nBianka_Kowalska & 0.533333 & 0.133333 \\\\\\\\\\nHubert_Baran & 0.833333 & 0.555556 \\\\\\\\\\nDaniil_Hardzetski & 0.611111 & 0.423077 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "our_results.to_latex()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
